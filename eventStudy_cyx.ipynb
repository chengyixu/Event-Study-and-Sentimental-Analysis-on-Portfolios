{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f520f274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f162d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals = pd.read_csv('fundamenals.csv')\n",
    "dividendsIDK = pd.read_csv('Dividend.csv')\n",
    "#merged_df = pd.read_csv('merged_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9323626",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fdde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dividendsIDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5d086",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals = fundamentals.rename(columns={\n",
    "    'tic': 'ticker',\n",
    "\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6bb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2e29d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(dividendsIDK, fundamentals, on='ticker')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d2b467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f17be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a602661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values distribution: \")\n",
    "print(df.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b796ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''drop ones with high percentage%'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9582b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['capgn','cheqv','div','divd','divsp','anncdate','cheqvpaydate','divdpaydate','adrrc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ab6d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values distribution: \")\n",
    "print(df.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['spcsrc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c607edf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Column datatypes: \")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04184bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb6c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa80311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0341ca37",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1adfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values distribution: \")\n",
    "print(df.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a26de2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dropna(subset=['cshoc', 'cshtrd', 'prcod', 'trfd', 'ggroup', 'gind', 'gsector', 'gsubind'], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Missing values distribution: \")\n",
    "print(df.isnull().mean())\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1be7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7e5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# further clean\n",
    "columns_to_delete = ['nrets_est', 'gvkey', 'iid', 'datadate']\n",
    "df = df.drop(columns=columns_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998bfaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f85717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert the \"evtdate\" column to a datetime type if it's not already\n",
    "df['evtdate'] = pd.to_datetime(df['evtdate'])\n",
    "\n",
    "# Subset the DataFrame to select data after 2010-01-01\n",
    "#subset_df = df[df['evtdate'] > '2020-01-01']\n",
    "\n",
    "subset_df = df[df['gsector'] == 45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ad87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Div_new.csv file into a DataFrame\n",
    "div_df = pd.read_csv(\"Div_new.csv\")\n",
    "\n",
    "columns_to_delete_new = ['uid']\n",
    "div_df = div_df.drop(columns=columns_to_delete_new)\n",
    "\n",
    "# Merge the datasets based on the \"ticker\" column\n",
    "merged_df = pd.merge(subset_df, div_df, on=\"ticker\")\n",
    "\n",
    "# View the merged DataFrame\n",
    "print(merged_df)\n",
    "\n",
    "merged_df['marketcap'] = merged_df['prccd'] * merged_df['cshoc']\n",
    "\n",
    "#df.to_csv('merged_df.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5a6842f3",
   "metadata": {},
   "source": [
    "# BEFORE EVENT HAPPENS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a71aa5de",
   "metadata": {},
   "source": [
    "### Predict ABRET using fundamentals before/after the event happens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa27681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# assuming the dataframe is named merged_df\n",
    "\n",
    "# Define the predictors\n",
    "predictors = ['dvi', 'eps', 'prccd', 'prchd', 'prcld', 'trfd', 'ggroup', 'gind', 'gsubind', 'cshtrd', 'marketcap']\n",
    "\n",
    "# Initialize a dictionary to hold the results\n",
    "regression_results = {}\n",
    "\n",
    "# Iterate over the event times\n",
    "for t in range(-10, 0):\n",
    "    # Select the rows for the given event time\n",
    "    df_t = merged_df[merged_df['evttime'] == t]\n",
    "    \n",
    "    # Form the regression formula\n",
    "    formula = 'abret ~ ' + ' + '.join(predictors)\n",
    "    \n",
    "    # Run the regression\n",
    "    result = smf.ols(formula, data=df_t).fit()\n",
    "    \n",
    "    # Store the results\n",
    "    regression_results[t] = result\n",
    "\n",
    "# Print the results\n",
    "for t, result in regression_results.items():\n",
    "    print(f'Event Time {t}:')\n",
    "    print(result.summary())\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9cf925e",
   "metadata": {},
   "source": [
    "### predcit car (same technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af1f45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Div_new.csv file into a DataFrame\n",
    "div_df = pd.read_csv(\"Div_new.csv\")\n",
    "\n",
    "columns_to_delete_new = ['uid']\n",
    "div_df = div_df.drop(columns=columns_to_delete_new)\n",
    "\n",
    "# Merge the datasets based on the \"ticker\" column\n",
    "merged_df_car = pd.merge(subset_df, div_df, on=\"ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d831ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_car['marketcap'] = merged_df_car['prccd'] * merged_df_car['cshoc']\n",
    "\n",
    "# Calculate cumulative abnormal return\n",
    "merged_df_car = merged_df_car.sort_values(by=['ticker', 'evtdate_x', 'evttime'])\n",
    "\n",
    "# Group by Ticker and evtdate, then calculate the rolling sum of 'abret' from evttime -10 to evttime -1\n",
    "merged_df_car['car'] = merged_df_car.groupby(['ticker', 'evtdate_x'])['abret'].transform(lambda x: x.rolling(10, min_periods=1).sum())\n",
    "\n",
    "# Select rows where evttime is -1 (the end of the window)\n",
    "car_df = merged_df_car[merged_df_car['evttime'] == -1]\n",
    "\n",
    "# Define the predictors\n",
    "predictors = ['dvi', 'eps', 'prccd', 'prchd', 'prcld', 'trfd', 'ggroup', 'gind', 'gsubind', 'cshtrd', 'marketcap']\n",
    "\n",
    "# Initialize a dictionary to hold the results\n",
    "car_regression_results = {}\n",
    "\n",
    "# Iterate over the event times\n",
    "for t in range(-10, 0):\n",
    "    # Select the rows for the given event time\n",
    "    df_t = merged_df_car[merged_df_car['evttime'] == t]\n",
    "    \n",
    "    # Form the regression formula\n",
    "    formula = 'car ~ ' + ' + '.join(predictors)\n",
    "    \n",
    "    # Run the regression\n",
    "    result = smf.ols(formula, data=df_t).fit()\n",
    "    \n",
    "    # Store the results\n",
    "    car_regression_results[t] = result\n",
    "\n",
    "# Print the results\n",
    "for t, result in car_regression_results.items():\n",
    "    print(f'Event Time {t}:')\n",
    "    print(result.summary())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76ae2465",
   "metadata": {},
   "source": [
    "# AFTER EVENT HAPPENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fc2c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "merged_df['marketcap'] = merged_df['prccd'] * merged_df['cshoc']\n",
    "\n",
    "# Define the predictors\n",
    "predictors = ['dvi', 'eps', 'prccd', 'prchd', 'prcld', 'trfd', 'ggroup', 'gind', 'gsubind', 'cshtrd', 'marketcap']\n",
    "\n",
    "# Initialize a dictionary to hold the results\n",
    "afterregression_results = {}\n",
    "\n",
    "# Iterate over the event times\n",
    "for t in range(0, 10):\n",
    "    # Select the rows for the given event time\n",
    "    df_t = merged_df[merged_df['evttime'] == t]\n",
    "    \n",
    "    # Form the regression formula\n",
    "    formula = 'abret ~ ' + ' + '.join(predictors)\n",
    "    \n",
    "    # Run the regression\n",
    "    result = smf.ols(formula, data=df_t).fit()\n",
    "    \n",
    "    # Store the results\n",
    "    afterregression_results[t] = result\n",
    "\n",
    "# Print the results\n",
    "for t, result in afterregression_results.items():\n",
    "    print(f'Event Time {t}:')\n",
    "    print(result.summary())\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8b91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Div_new.csv file into a DataFrame\n",
    "div_df = pd.read_csv(\"Div_new.csv\")\n",
    "\n",
    "columns_to_delete_new = ['uid']\n",
    "div_df = div_df.drop(columns=columns_to_delete_new)\n",
    "\n",
    "# Merge the datasets based on the \"ticker\" column\n",
    "merged_df_car = pd.merge(subset_df, div_df, on=\"ticker\")\n",
    "merged_df_car['marketcap'] = merged_df_car['prccd'] * merged_df_car['cshoc']\n",
    "\n",
    "\n",
    "# Calculate cumulative abnormal return\n",
    "merged_df_car = merged_df.sort_values(by=['ticker', 'evtdate_x', 'evttime'])\n",
    "\n",
    "# Group by Ticker and evtdate, then calculate the rolling sum of 'abret' from evttime -10 to evttime -1\n",
    "merged_df_car['car'] = merged_df_car.groupby(['ticker', 'evtdate_x'])['abret'].transform(lambda x: x.rolling(10, min_periods=1).sum())\n",
    "\n",
    "# Select rows where evttime is -1 (the end of the window)\n",
    "car_df = merged_df_car[merged_df_car['evttime'] == -1]\n",
    "\n",
    "# Define the predictors\n",
    "predictors = ['dvi', 'eps', 'prccd', 'prchd', 'prcld', 'trfd', 'ggroup', 'gind', 'gsubind', 'cshtrd', 'marketcap']\n",
    "\n",
    "# Initialize a dictionary to hold the results\n",
    "aftercar_regression_results = {}\n",
    "\n",
    "# Iterate over the event times\n",
    "for t in range(0, 10):\n",
    "    # Select the rows for the given event time\n",
    "    df_t = merged_df_car[merged_df_car['evttime'] == t]\n",
    "    \n",
    "    # Form the regression formula\n",
    "    formula = 'car ~ ' + ' + '.join(predictors)\n",
    "    \n",
    "    # Run the regression\n",
    "    result = smf.ols(formula, data=df_t).fit()\n",
    "    \n",
    "    # Store the results\n",
    "    aftercar_regression_results[t] = result\n",
    "\n",
    "# Print the results\n",
    "for t, result in aftercar_regression_results.items():\n",
    "    print(f'Event Time {t}:')\n",
    "    print(result.summary())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c34073ca",
   "metadata": {},
   "source": [
    "# test the significances of the variables above"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71f3e4a1",
   "metadata": {},
   "source": [
    "### best day to invest in Company after/before the event happens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "93d468e7",
   "metadata": {},
   "source": [
    "# compare the outcomes when inputs are the same\n",
    "# rank them"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "020a1171",
   "metadata": {},
   "source": [
    "### compare the results and conclude\n",
    "1. if knowing the event_div_cut will happen (long time ago, as long as 10 days), what is the best day to invest?\n",
    "2. after the event_div_cut happened (as long as 10 days), what is the best day to invest?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d57d07d",
   "metadata": {},
   "source": [
    "# find the best day"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b844c28e",
   "metadata": {},
   "source": [
    "### Pre- EVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac180e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intercepts\n",
    "abret_intercepts = {t: result.params['Intercept'] for t, result in regression_results.items()}\n",
    "car_intercepts = {t: result.params['Intercept'] for t, result in car_regression_results.items()}\n",
    "\n",
    "# Sort by intercept\n",
    "abret_sorted = sorted(abret_intercepts.items(), key=lambda item: item[1])\n",
    "car_sorted = sorted(car_intercepts.items(), key=lambda item: item[1])\n",
    "\n",
    "# Print the sorted results\n",
    "print(\"Ranking based on the value of the intercept for 'abret':\")\n",
    "for t, intercept in abret_sorted:\n",
    "    print(f'Event Time {t}: Intercept = {intercept}')\n",
    "    \n",
    "print(\"\\nRanking based on the value of the intercept for 'car':\")\n",
    "for t, intercept in car_sorted:\n",
    "    print(f'Event Time {t}: Intercept = {intercept}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f973844d",
   "metadata": {},
   "source": [
    "### After -EVENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95706eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract intercepts\n",
    "abret_intercepts = {t: result.params['Intercept'] for t, result in afterregression_results.items()}\n",
    "car_intercepts = {t: result.params['Intercept'] for t, result in aftercar_regression_results.items()}\n",
    "\n",
    "# Sort by intercept\n",
    "abret_sorted = sorted(abret_intercepts.items(), key=lambda item: item[1])\n",
    "car_sorted = sorted(car_intercepts.items(), key=lambda item: item[1])\n",
    "\n",
    "# Print the sorted results\n",
    "print(\"Ranking based on the value of the intercept for 'abret':\")\n",
    "for t, intercept in abret_sorted:\n",
    "    print(f'Event Time {t}: Intercept = {intercept}')\n",
    "    \n",
    "print(\"\\nRanking based on the value of the intercept for 'car':\")\n",
    "for t, intercept in car_sorted:\n",
    "    print(f'Event Time {t}: Intercept = {intercept}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44ef64a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3cf6e71",
   "metadata": {},
   "source": [
    "# Sentimental Analysis using\n",
    "sec edgar parsing python  AND\n",
    "sec-api Â· PyPI\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
